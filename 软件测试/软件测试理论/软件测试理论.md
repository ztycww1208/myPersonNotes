# 软件测试理论

## 1. 前言

### 1.1 什么是软件测试

> 软件测试是一系列过程活动，包括软件测试需求分析，测试计划设计，测试方案设计，测试用例设计，执行用例等，它贯穿于项目的整个生命周期，在项目的每一个阶段都需要进行不同目的和内容的测试活动，以保证各个阶段的正确性

### 1.2 为什么进行软件测试

> 假如你使用的是一个未经过测试的软件, 那么在软件使用的过程中, 有可能出现卡顿卡死, 密码被盗, 资金被转等问题, 而软件测试工程师正是未了规避这一问题而出现的

### 1.3 软件项目的初期过程

略



## 2.研发模型

### 2.1 瀑布模型

> `计划--需求--设计--编码--测试--运维`

>==特点==:
>
>线性化的研发模型
>
>各个阶段都具有`里程碑`的特征
>
>基于文档的驱动
>
>严格的阶段评审机制

> ==优点==:
>
> 有利于大型软件开发过程中人员的组织和管理
>
> 有利于开发方法和工具的使用
>
> 提高了软件的质量和效率
>
> ==缺点==:
>
> 不灵活

> `里程碑`：就是项目或版本过程中的各个时间或任务节点，比如：版本发布，需求定稿等等

### 2.2 V模型

> `用户需求--需求分析--概要设计--详细设计--编码--单元测试--集成测试--系统测试--验收测试`

> `优点:`
>
> 测试被分为若干级别, 能够提高软件的质量
>
> 测试和开发级别一一对应
>
> `缺点:`
>
> 忽略了测试对象不仅包括程序, 还包括文档
>
> 验收测试是最后阶段, `需求阶段的问题`只能到验收测试才能被发现

### 2.3 W模型(双V模型)

> `优点`:
>
> 又称双V模型, 测试和开发是同步进行的
>
> 测试对象不仅包括程序, 还包括文档
>
> 尽早投入测试可以降低开发成本
>
> ==缺点:==
>
> 无法迭代 , 这是相对的 , 不是绝对的

### 2.4 X模型

> 最早引入探索性测试研发模型
>
> 软件分为几个片区, 然后集成在一起形成最终的软件

### 2.5 螺旋模型

> 非线性化的研发模型
>
> 引入了风险管理 , 进行评估

### 2.6 快速原型

> 又称原型定义 , 非线性化研发模型 , 主要适用于小公司 , 客户到了最后才知晓软件的最终模样,先做成一个demo(模型样板), 给客户进行产品预演

### 2.7 迭代开发

> 每次只设计和实现产品的一部分，通过逐步完成的方法叫`迭代开发`，每次设计和实现一个阶段叫
> 做`迭代`

> ==优点== ：
>
> `降低需求变更的成本`
>
> `得到早期的用户反馈`
>
> `持续的测试和集成`

### 2.8 敏捷开发

> 敏捷开发以用户的需求进化为核心，采用迭代，循序渐进的方法进行软件开发

> ==敏捷开发的核心价值观==:
>
> 个体与交互 于==重于==过程和工具
>
> 可用的软件 于==重于==完备的文档
>
> 客户协作 于==重于==合同谈判
>
> 响应变化 于==重于==遵循计划

> ==优点==:
>
> 敏捷确实是项目进入实质开发的迭代阶段，用户很快可以看到一个基线架构版的产品，敏捷注重
>
> 市场快速反应能力
>
> ==缺点==:
>
> 敏捷注重人员的沟通，忽略文档的重要性，若有项目人员流动太大，又给维护带来不少难度，特
>
> 别项目存在新手比较多时，老员工比较累
>
> ==tips==:
>
> 敏捷和迭代虽然不一样，但是他们是密不可分的，迭代和敏捷开发方式的结合，既保证了产品的
> 质量又在项目产品的持续改进中具有一定的优势，吸取精华，剔除糟粕，只有这样，项目才会达
> 到趋于完美的程度



## 3. 软件测试的基础

### 3.1 软件测试的定义

> 在规定的条件下操作程序，发现缺陷，评估软件质量

> 测试的依据：需求，所有的测试都需要追溯到用户需求（测试原则一）

### 3.2 软件测试的目的

> `尽可能多`的发现软件的缺陷，预防缺陷，对软件的质量进行评估，以提高软件的质量
>
> 是尽可能多的发现软件的缺陷，是不可能发现全部的错误的



### 3.3 软件测试的范围或对象

> 程序, 文档, 数据

### 3.4 软件测试的原则

>==1.所有的测试都应该追溯到用户需求==
>
>答：`需求`是软件测试的依据
>
>==2.应当把尽早地和不断的测试作为软件测试的座右铭==
>
>答：尽早地测试能够降低开发成本，不断地测试更能提高软件的质量
>
>==3.完全测试是不可能的，测试需要终止==
>
>答：出于成本考虑和现实考虑
>
>==4.软件测试无法显示潜在的缺陷==
>
>答：缺陷有时候需要在特定的情况下才会出现
>
>==5.充分注意群集现象==
>
>答：二八定律，80%的缺陷出现在20%的模块，发现bug越多的模块，残留的缺陷也越多
>
>==6.避免程序员检查自己的程序==
>
>答：开发沿用之前的开发思路，去找问题很难发现问题，人从心理学认为自己开发的程序是最好的，会跳过程序的检查
>
>==7.避免测试的随意性==
>
>答：测试需要计划，节约人力和成本

### 3.5 软件测试的风险

> `人员风险、质量风险、成本风险、变更风险、进度风险`

### 3.6 测试工程师所具备的素质

> ==综合素质==:
>
> 1.细心，耐心，责任心，自信心
>
> 2.沟通能力，语言以及文字表达能力
>
> 3.团队协作能力
>
> 4.发现问题的敏锐程度以及观察能力
>
> 5.逻辑思维能力和发散性思维能力
>
> 6.具有丰富的软件测试经验
>
> ==专业素质==:
>
> 1.熟悉软件研发流程以及测试流程的知识
>
> 2.熟悉软件理论知识，测试技术和方法，测试文档的编写能力
>
> 3.掌握测试工具：管理工具，自动化工具，集成工具，性能工具，安全工具...
>
> 4.计算机相关知识：数据库，操作系统，网络基础，开发语言

### 3.7 软件的生命周期

> ==需求== -- ==设计== -- ==编码== -- ==测试== --==维护== -- ==升级== -- ==废弃==

> 项目的需求阶段，产品，开发，测试都一起参与，对应的输出文档
>
> 产品：用户需求，产品需求，需求规格说明书
>
> 开发：（概要设计）
>
> 测试：需求分析文档

### 3.8 软件测试的流程

> ==需求分析== -- ==测试计划== -- ==测试方案== -- ==测试用例== --==测试执行== -- ==测试报告==

### 3.9 项目中的成员

>1.项目经理(PM)
>
>2.架构师（SE）
>
>3.程序员(程序猿，码农)
>
>4.软件测试工程师：初级、中级、高级、技术专家；测试经理，交付经理，部门经理
>
>5.资料工程师(大公司才有的职位)
>
>6.配置管理员(CMO)
>
>7.QA（大公司才有的职位）
>
>8.产品经理(BA)
>
>9.UI设计(界面设计，图标设计，logo等)
>
>10.DBA：数据库管理员

## 4. 软件测试的分类

### 4.1 按照==阶段==划分

> ==单元测试==--==集成测试==--==系统测试==--==验收测试==

> ==单元测试==:
>
> 对于软件中最小的可测单元进行检查和验证：如 ：JAVA语言中的类，C语言中的函数，UI界面中
> 的窗口
>
> 依据： ==详细设计==
>
> 谁测试：90%是开发人员测试，因为必须具备代码阅读能力
>
> 单元测试能够发现80%左右的缺陷
>
> 单元测试工具：JAVA语言中的junit，python语言中的unittest，Pytest
>
> 侧重于检查程序的内部结构，逻辑控制以及异常处理

> ==集成测试==:
>
> 在单元测试基础上，把模块组装成系统或者子系统，然后进行测试，又称  ==联合(组装)测试== 。
>
> 依据：==概要设计==
>
> 谁来做：软件测试工程师
>
> 侧重检查`模块和模块之间的接口`以及`接口数据`传输的正确性
>
> 分类：
>
> ==非增量式集成==：又称一次性集成
>
> ==增量式集成== ：
>
> - 自顶向下增量式集成需要编写： ==测试桩==
>
> - 自底向上增量式集成需要编写： ==驱动程序==

> ==系统测试==:
>
> 将软件、硬件、网路等设备连接进行测试
>
> 依据：==需求规格说明书(产品经理编写的需求文档)==
>
> ==分类或范围== ：
>
> ==功能测试== ：测试软件的功能是否正常实现
>
> ==性能测试== ：测试系统所消耗的时间和资源
>
> ==压力测试== ：系统在什么情况下会到达极限
>
> ==容量测试== ：测试系统最大的访问用户数
>
> ==安全性测试== ：验证系统是否容易被攻击
>
> ==可用性测试== ：测试系统使用是否方便
>
> ==GUI测试== ：界面测试
>
> ==安装测试== ：安装和卸载
>
> ==配置测试== ：测试系统软件和硬件的最优配置
>
> ==异常测试== ：检查系统对异常情况下的处理
>
> ==备份测试== ：系统的数据备份
>
> ==健壮性测试== ：用于测试系统在出现故障时，是否能够自动恢复或者忽略故障继续运行
>
> ==文档测试== ：测试帮助文档
>
> ==在线帮助测试== ：联系产品的售后客服
>
> ==网络测试== ：不同网络下的使用情况：wifi，5g，4g，3g，2g，有线
>
> ==稳定性测试== ：软件长时间运行，系统是否能够运行正常

> ==验收测试==:
>
> 依据： ==用户需求== ，需要用户参与
>
> 分类：
>
> ==正式验收测试==
>
> ==非正式验收测试== ： ==阿尔法测试== （α测试）和 ==贝塔测试== （β测试）
>
> ==阿尔法测试和贝塔测试区别== ：
>
> 阿尔法测试是由 ==公司内部人员== 测试，贝塔测试是由 ==典型用户测试==
>
> 阿尔法测试 ==遇到bug可以控制== ，贝塔测试 ==遇到bug不可控==
>
> 阿尔法测试使用的是 ==测试环境== ，贝塔测试使用的是 ==现网环境== ，又称线上环境，公网环境，互
> 联网，生产
>
> 阿尔法测试发现问题 ==能够及时修复== ，贝塔测试需要 ==统一收集问题然后集中修复==
>
>   
>
> 验收测试的缺陷密度：小于0.2个/kloc



> 验收测试不通过，测试人员怎么做？
>
> - 回溯Bug产生的原因，避免下一次发生同样的问题
>
> Bug怎么进行回溯：
>
> 1. 分析Bug是什么原因产生的
>    1. 如果是容易发生的，并且测试用例中有涉及，要追究相应测试人员的责任
>    2. 如果是偶发性，隐藏比较深，也要记录，在日后的测试中加以注意
> 2. 总之，如果是能力范围内，能够找到却没有找到的bug，就要追究相关测试人员的第一责任，如果非能力范围内，要引以为戒，吸取教训，积累经验。

### 4.2 按照是否运行程序划分

>==动态测试== ：运行被测试的程序
>
>==静态测试== ：静态的去查看文档，或者进行代码走查，代码审查

### 4.3 按照技术划分

>==黑盒== ：不关注软件的内部逻辑结构，只关注输入和输出，关注功能和性能，适用于系统测试，验收测试
>
>==白盒== ：与黑盒相反，适用于单元测试
>
>==灰盒== ：介于白盒和黑盒之间，适用于集成测试，接口测试

### 4.4 其他划分

> 1. ==回归测试== ：执行上一轮测试中，未通过的测试用例，查看bug是否修复，或者修复的bug是
>     否引入新的问题
>
>     回归测试的`过程`：
>     
>     - 首先需要回归bug，再测试与bug相关联的功能模块
>     - 执行优先级高的用例，如果时间充足，继续执行中优先级用例
>     - 关注bug出现频率高得模块
>     
> 2. ==冒烟测试== ：又称**BVT测试**或者**预测试**，在正式测试之前，抽取项目中基本流程用例（大概
>     10%左右），全部执行通过，`如果冒烟测试不通过，项目直接打回`，冒烟测试之前需要安装环
>     境，测试时间**半天或一天**
>
> 3. ==兼容性测试== ：将软件运行在不同的设备上，保证软件在各个设备上均提供正常的服务，如：
>     web项目测试不同的浏览器，app项目测试不同型号的手机或者平板 
>
>   **兼容性测试时间**：功能稳定之后，一般在第三轮测试

> `如果冒烟测试不通过，项目直接打回`:  时间紧的话，开发要加班改，如果不能改，会影响整个项目的计划，申请推迟正式测试开始时间。

> 4  **自动化测试**在什么时候开始?
>
> - 冒烟测试和回归测试
>
> 5  资料测试包括哪些？谁来测试，资料测试时间
>
> - `资料测试`：测试方案、测试用例、版本说明书，安装说明书等文档的评审
> - 方案、用例的评审就是在 **测试文档**
> - 版本说明书、安装说明书`在版本发布之前`进行测试
> - 测试资料是谁写的：版本、安装是开发写的
> - 测试资料需要设计测试用例吗？
>   - 严格意义上讲是需要的
>   - 针对特定的软件，比如工具类型的，或大型软件
>
> 6  



## 5.需求分析

### 5.1 什么是需求分析

>主要是解决测试什么的问题，明确测试的地方
>
>以需求规格说明书为基础，进行细化和分解

### 5.2 需求分析的范围

> 主要指==明确的==和==隐含的==需求

> 隐含的需求：即隐形需求
>
> 就是需求中没有明确要求，但是按照约定俗成的规则或日常习惯必须满足的需求。
>
> 例如：在项目中通过手机号码注册用户，需求中只会描述符合手机号码规则的用户注册成功，不会明确的说手机号长度11位

### 5.3 需求分析的责任人和时间

>谁来做：`有经验的软件测试工程师`
>
>需求分析的时间：通常占项目周期的`10%-20%`左右的时间（工作日）

### 5.4 需求分析的文档和工具

> 输入文档：`需求规格说明书（FRS）`
>
> 输出的文档：`测试需求分析文档`，工具：mindmanager，xmind

### 5.5 需求分析的评审人

> 组内的软件测试工程师，产品经理，开发代表，测试经理，项目经理，QA

### 5.6 需求分析的特征

>==需求项必须是可核实的==
>
>==需求分析需要指出正确条件和错误条件==
>
>==需求分析不包含具体数据==

### 5.7 需求分析的方法

>==测试要点==
>
>==功能交互==
>
>==质量特性==
>
>==测试类型== （主要指的是不同类型的测试如：功能，兼容性，性能，自动化，安全...）

### 5.8 需求分析的过程

### 5.9 需求分析举例



## 6. 测试计划

### 6.1 编写人和时间

>编写人： ==测试经理== 或者 ==测试组长==
>
>编写时间：需求分析完成后，时间==2 - 5== 天，在整个测试过程中处于 改 ==不断修改== 的状态，保证测
>试计划满足实际需求

> 项目进度和测试计划不一致时，就需要修改测试计划

### 6.2 参考依据和读者对象

>参考依据： ==需求分析的结果== ，==项目计划==（可能还会涉及到需求分析表，概要设计）
>
>读者对象：
>
>1.上：项目经理
>
>2.中：开发经理，产品经理，QA
>
>3.下：组内的软件测试工程师，组外的其他项目测试经理

### 6.3 如何制定测试计划

> 认真做好测试资料的搜集工作 , 主要搜集人和设备
>
> 明确测试的目的 , 主要是时间目标和质量目标
>
> 坚持5W原则 , 明确测试的内容和过程:
>
> why : 测试的目的
>
> what : 测试的范围
>
> when : 测试的时间
>
> who : 测试的参与人
>
> where : 项目中输出文档 , 软件包存放的位置

### 6.4 测试计划中包含的内容

> ==项目概述 , 范围和目的 , 测试通过的准则 , 读者对象 , 测试的参考资料 , 测试策略 , 软件环境 , 硬件环境 , 启动条件 , 结束条件 , 测试周期 , 人力投入 , 任务分配以及进度安排 , 测试风险==

#### 6.4.1 测试策略

> 又称==测试类型== , 主要指的是冒烟测试，功能测试，回归测试，兼容性测试，性能测试，接口测
> 试，安全测试...

#### 6.4.2 测试的启动条件和结束条件

>==启动条件== ：
>
>1.测试用例编写完成，并通过评审
>
>2.开发编码完成，并通过自测
>
>3.开发提交了**转测试**申请单以及相关配置        ---转测试进行的是冒烟测试
>
>4.测试环境搭建完毕，冒烟测试通过
>
>==结束条件== ：
>1.测试任务全部完成，人力投入充分
>
>2.需求覆盖率一般达到100%，测试用例通过率一般达到100%
>
>3.缺陷密度达到预定标准
>
>​	3.1预定标准：高验收标准：3-5个，一般验收标准：6-10个
>
>​	3.2缺陷密度计算方式：缺陷密度=bug总数/总代码量，代码量单位：KLOC，千行
>
>4.bug趋势呈现正态分布或者`收敛状态`
>
>5.需求规格说明书所有的功能全部正确实现
>
>6.交付件齐全，验收测试通过
>
>  
>
>bug在项目中不能正常收敛的原因：
>
>- 需求不断变更是很可能的原因
>- 开发人员水平较低，修复一个bug引发出若干 其他bug

## 7. 测试方案

### 7.1 概念

> 测试方案是对需求分析结果进行细化和分解得到的`功能点`，主要解决 ==怎么做== 的问题

> `功能点`：即测试点，对功能的细分，功能的各种情况，相当于测试用例的标题
>
> `测试方案和测试策略的区别`：
>
> 测试方案：包括的内容是 测试点 ，主要指导怎么测的问题
>
> 测试策略：即测试方法，比如功能测试，性能测试，兼容性测试等，并指出用的什么工具
>
>  
>
> 一个项目的测试用例怎么估算，测试点数等于用例数吗？
>
> 答：这需要根据测试人员写的用例颗粒度粗细来定，如果是比较细的话是可能等于的。



### 7.2 编写人和时间

>时间：测试计划编写完成后，大型项目： ==两周左右== ，中小型项目：==一周左右==
>
>编写人：具有 ==丰富经验== 的软件测试工程师，根据自己分配的模块进行
>
>==tips== ：
>
>真实项目中大多数公司（90%）是没有测试方案，将测试方案和需求分析合并在一起称为测试设
>计，测试方案主要是围绕测试类型进行展开分析，如：自动化测试，接口测试，性能测试，安全
>测试...

### 7.3 评审人

> 组内的软件测试工程师，产品经理，开发代表，测试经理，项目经理，QA

### 7.4 常见的测试点

#### 7.4.1 登录

<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200812204344992.png" alt="image-20200812204344992" style="zoom: 67%;" />

#### 7.4.2  验证码

<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200812204437416.png" alt="image-20200812204437416" style="zoom: 67%;" />

#### 7.4.3 删除

#### 7.4.4 新增

#### 7.4.5 修改

<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200812204530626.png" alt="image-20200812204530626" style="zoom:67%;" />

#### 7.4.6  查询

#### 7.4.7  翻页

<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200812204619006.png" alt="image-20200812204619006" style="zoom:67%;" />

#### 7.4.8  统计

#### 7.4.9  日历控件

#### 7.4.10  导出

#### 7.4.11  导入

#### 7.4.12  支付

#### 7.4.13  列表

<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200812204558645.png" alt="image-20200812204558645" style="zoom:67%;" />

#### 7.4.14  购物车



#### 7.4.15  微信红包

#### 7.4.16  电梯测试

#### 7.4.17  水杯测试



## 8. 测试用例

### 8.1 概念

>==测试方案== 和 ==测试用例== 均属于测试的设计文档，测试用例描述了输入动作和一个期望结果，目
>的是确定程序的某个功能是否正常工作的

### 8.2 参考依据

> ==需求分析文档 , 测试方案，需求规格说明书==
>
> 主要还是参考需求分析完成后的测试点，少量参考需求规格说明书



### 8.3 编写人和时间

>==编写人==：具有丰富经验的软件测试工程师
>
>==编写时间==：测试方案编写完成并通过评审，编写时间占整个项目周期的 ==30%== 左右

### 8.4 编写工具和输出文档

>输出文档：` 测试用例`
>编写工具： `excel` 、word、zentao、bugfree、testlink...

### 8.5 评审人

> 组内的软件测试工程师，开发代表，产品经理，测试经理，项目经理，QA

### 8.6 测试用例的组成

>`用例编号，功能模块，标题，优先级，预置条件，操作步骤，预期结果，设计人，设计时间，备注`

#### 8.6.1 用例标题

>不能重复
>
>格式：项目名-模块名-编号 如：Weixin-faxian-0001(这里模块写一级模块名)

#### 8.6.2 功能模块

>主要是为了方便分配任务，知道用例的所属路径，一般写二级模块，也写三级模块
>
>如：朋友圈-评论

#### 8.6.3 标题

> 1 `在什么地方 +  条件 +  结果` 如：在QQ登录界面，输入正确的用户名和正确的密码，登录成功准 
>
> 2.`标题规范标准 ：`
>
> 1.相同模块下标题不能重复
>
> 2.标题中不能写bug
>
> 3.标题中不能有歧义 如：大概，可能，也许，是否等
>
> 4.标题中不能涉及具体的数据，具体的数据在 骤 预置条件和操作步骤 内
>
> 5.标题和预期结果相互呼应
>
> 6.标题中没有句号，最多一个逗号（不是必须）
>
> 7.标题长度不能超多24个字符（不是必须）

#### 8.6.4 优先级

> 1.`目的`：是为了测试时间不充裕的情况下，按照`优先级比例`抽取 主要功能模块用例 进行执行，如：
> `冒烟测试，回归测试`
>
> 2.根据 `重要性` 和 `使用频率 `来确定用例的优先级，两高得高，一高一低得中，两低得低
>
> 3.优先级高中低比例：` 1:3:1`
>
> 4.正常场景用例比异常场景用例高一个等级

#### 8.6.5 预置条件

> 1 在具体的测试数据之前需要准备的前提条件，如：登录系统，必须提前注册账号
>
> 2 `包含具体的测试数据 `
>
> 3 测试时需要的环境信息

#### 8.6.6 操作步骤

> 1.具体的功能界面输入的数据和操作的按钮
>
> 2.操作步骤 `包含具体的测试数据 `

#### 8.6.7 预期结果

> 用例的期望结果，指明测试用例执行后要达到什么样的结果

### 8.7 测试用例的`颗粒度`划分

> `定义`：颗粒度大小就是用例的粗细程度
>
> `划分标准`：颗粒度可以从很多方面考虑比如：覆盖度，一条用例的步骤，用例数量，划分为`粗粒度`和`细粒度`,但是没有绝对的标准
>
> 决定颗粒度大小的`因素`：
>
> | 因素         | 粗粒度                                         | 细粒度                                             |
> | ------------ | ---------------------------------------------- | -------------------------------------------------- |
> | 时间、资源   | 时间短，项目紧，编写用例和评审时间短，人手短缺 | 项目周期较长时，人员配备充足                       |
> | 执行用例人员 | 适合有测试经验的                               | 对于新手，比较容易理解，易上手                     |
> | 需求变更     | 可比较灵活的覆盖需求，易于维护                 | 适合需求变更较少的时候，不易于维护                 |
> | 风险         | 漏测，依赖于有经验测试人员的能力               | 测试用例太多，测试人员成测试机器，容易跳过部分测试 |
>
> 

### 8.8 测试用例的`设计要点`

> 1.用最少的测试用例尽可能全面的覆盖所有需求
>
> 2.穷举测试数据太大，完全测试是不可能的，测试需要终止

 

> 不能发现bug的测试用例不是好的测试用例吗？
>
> 一条好的测试用例：
>
> `内容不冗余`，
>
> `功能覆盖不遗漏`，
>
> `任何人都能执行`: 内容要简洁，完整，准确，易理解，格式要一致（和提单的5C原则一样）
>
> 软件测试的目的是评估软件质量，设计测试用例的目的也就是评估软件质量，而不是根据是否能发现bug判断



## 9. 黑盒测试用例设计方法

### 9.1 概念

> `黑盒测试` ，又称 `功能测试` ，数据驱动测试或者基于 `需求规格说明书` 的测试，是从用户观点出发的测试



### 9.2 等价类

>    1.定义：把所有可能输入的数据划分为若干部分，然后从子集中抽取少量具有代表性的数据作为测试用例
> 2. `有效等价类`：指对程序的规格说明书来来说是合理的，这些数据构成的集合称为有效等价类
>
> 3. `无效等价类` ：指对程序的规格说明书来说是不合理无意义的输入数据所构成的集合称为无效的等价类
>
> 4. `划分标准` ：
>
>       1. `完备测试 `：将集合划分成不相交的一组子集，而子集的并集是整个集合
>       2. `避免冗余` ：子集互不相交
>
> 5. 划分方法:
>
> 6. 设计原则
>
>    1.为每一个等价类规定一个 `唯一编号`
>
>    2.设计一个新的用例，使其 `尽可能多的覆盖尚未被覆盖类的有效等价类` ，重复这一步骤直到所有的 止 `有效等价类都被覆盖为止 `
>
>    3.设计一个新的用例，使其  `仅覆盖一个尚未被覆盖的无效等价类 `，重复这一步骤直到所有的 `无效等价类都被覆盖为止`

### 9.3 边界值

> `边界值是对等价类方法的补充`

>`上点` ：取值范围的端点，不用关注端点取值到底是有效还是无效
>
>`离点` ：取值范围端点左右两边的值
>
>`内点` ：取值范围大概中间的值
>
>`弱覆盖` ：上点有效，离点无效，上点无效，离点有效

### 9.4 错误推错法

> 基于 `经验` 和 `直觉` 推测程序中所有可能存在的各种错误，从而针对性的设计测试用例。如：
>
> 1.对于日历控件中需要考虑闰年的2.29和平年的2.28
>
> 2.对于多条相同数据怎样排序
>
> 3.密码中加入空格
>
> 4.密码不支持拷贝，但是可以在密码输入框中粘贴内容
>
> 5.两个用户删除同一条数据，一个成功，一个失败
>
> 6.不勾选数据，删除数据，应当有相应的提示
>
> 7.新增时，考虑数据的唯一性
>
> 8.查询数据时，输入通配符，只能查询出包含通配符%和_的数据
>
> 9.app软件在使用过程中来电话，软件能够正常使用
>
> 10.退出用户登录界面，使用浏览器的返回按钮，不能返回至登录界面

### 9.5 场景法

> 场景法又称流程分析法，是将软件系统的某个流程看成路径，使用路径分析的方法来设计测试用
> 例，根据用例顺序依次进行组合，使得流程的各个分支都能覆盖
>
> `基本流` ：主场景，流程的主干
>
> `备选流 `：可选场景，流程的分支

### 9.6 用例设计方法选择策略

> 1.首先进行 ` 等价类` 的划分，将无限的测试变成有限
>
> 2.然后结合`边界值` 分析方法进行补充
>
> 3.然后使用 `错误推错法` 追加一些异常场景的测试用例
>
> 4.对于业务流程清晰的系统，可以采用 `场景法` 贯穿整个测试流程（主要用于冒烟测试和回归测试）



## 10. 测试执行

>`概念` ：根据编写的测试用例，按照用例步骤进行执行，查看预期结果和实际结果是否一致，如果不一致则为bug（缺陷）
>
>`参考依据 `：测试用例
>
>`执行人` ：软件测试工程师
>
>`开始时间` ：测试用例编写完成并通过评审，且达到测试执行的启动条件
>
>`时间周期` ：占整个项目周期的 ` 40%` 左右时间
>
>测试执行过程中时间安排，假设项目周期为三个月（66天），66*40%=26
>
>测试执行分为3轮测试，时间安排如下：13:8:5------------->按照 `5:3:2` 的比例进行安排
>
>测试执行分为4轮测试，时间安排如下：10:8:5:3----------->按照 ` 4:3:2:1` 的比例进行安排

### 10.0  测试环境搭建

> 谁搭建：测试组长或测试经理
>
> 时间：正式测试之前
>
> 搭建在哪里：
>
> - 测试环境会不会在虚拟机上搭建？
>   - 不会，可以是在阿里云上面租用
>   - 部署在我们公司机房的物理机上
>
> 搭建步骤：
>
> - 谁提供：开发人员，后续维护由测试人员
> - 例如：
>   1. 上传项目包
>   2. 安装 apache,mysql,php
>   3. 修改apache 的配置文件，因为php无法直接调用apache
>   4. 把安装包放到/var/www/html 下
>   5. 解压、赋权
>   6. 浏览器远程安装
>
> 如果环境处理问题，开发人员怎么处理：
>
> - 自己尝试解决，通过查看后台日志
>   - mysql  的日志路径：tail   -f   /etc/my.cnf  和  tail   -f   /var/log/mysqld.log
>   - Apache  的日志路径： tail  -f   /etc/httpd/log/error_log
>   - Tomcat  的日志路径：tail   -f   /usr/local/tomcat80/logs/catalina.out

### 10.1 测试用例的执行结果状态

> `new` ：用例编写完成，未开始执行的状态
>
> `pass` ：执行用例预期结果和实际结果一致
>
> `fail` ：执行用例预期结果和实际结果不一致
>
> `block` ：当因为软件有缺陷妨碍了测试用例的执行，并且该缺陷不是该用例的关注点
>
> `investigate` ：当用例在执行过程中需要消耗较多的时间来观察期间的结果

> `无效的测试用例`包括：废弃，需求变更，设计重复，或者对需求理解有偏差
>
> 用于需求阶段：变更，废弃
>
> 需求分析阶段：理解错误，重复
>
> 
>
> `在提交bug前，发现无效测试怎么处理？`
>
> 在写测试用例的时候，发现需求变更怎么处理？
>
> 发现无效，说明需求已经知道了，按需求来，没用的就不写，丢弃

> 在提交bug后，发现无效用例怎么处理？
>
> 答：bug打回关闭，（让开发人员打回吗），填写关闭的原因

### 10.2 测试执行过程中的注意事项

> 搭建软件测试环境
>
> 测试用例需要全部执行
>
> 不能忽视任何偶现的Bug
>
> 加强测试过程中的记录
>
> 提交缺陷和开发人员关系处理恰当
>
> 提交一份优秀的问题报告单
>
> 及时更新测试用例（执行测试用例时，不要及时填写用例的执行装态）

 ### 10.3 提交的缺陷，开发不认可，怎么处理？

> 1 首先进行`自我检查`，依据需求确定该缺陷是否有问题
>
> 2 确定是问题，拿出依据与开发人员`有理有据的沟通`
>
> 3 沟通无效，告知测试经理，将`问题升级`，提交到项目组`变更控制委员会`CCB进行裁决是否为问题

> 不管是什么问题，首先沟通，然后找出问题的原因，再找到对应负责人，
>
> 比如是需求问题，先跟产品反应能否澄清，甚至到客户确认

### 10.4 缺陷的分布特征

> 1 群集现象（二八定律）
>
> 2 测试进行的越多，新的缺陷就越难被发现，此时需要`拓展测试的思路`，寻找新的突破点
>
> 3 并非所有的缺陷都需要修复
>
> ​		修复风险太大，不值得修复
>
> ​		没有足够的时间进行修复，并且遗留的bug不会影响版本发布的新功能

> 拓展测试的思路：比如：`交叉测试`（自己设计的用例，测试时会跟着设计时的思路，所以交叉是一个好办法，但是如果说用例颗粒度 很细的话，是没有什么效果的，谁执行都一样）
>
>  
>
> 各个阶段bug发现的比例
>
> 系统测试之前能够发现80%缺陷
>
> 

### 10.5 测试执行过程中发现bug太多，你会怎么处理？

> 1.冒烟测试进行的不充分，不彻底
>
> 2.发现bug越多的模块，残留的缺陷也越多，同时说明开发编码质量太差，会影响到测试的质量和效率
>
> 3.我们需要将版本打回，要求开发人员自测，自测通过后再提交代码

### 10.6 幽灵bug的处理方法？

> 1.截图，保留证据，必要时录制视频，抓包，查看日志文件
>
> 2.在本机进行多次尝试该问题，若能够出现问题，则记录
>
> 3.若本机不能重现，在其他电脑上尝试重现是否能够出现
>
> 4.在其他电脑上无法重现，但是问题比较严重，找到开发人员进行协助定位
>
> 5.对于难以重现的问题，需要将问题单挂起，看后续版本是否存在，后续版本如果不存在，则关
>
> 闭bug

### 10.7 缺陷的组成

> `缺陷ID，缺陷标题，缺陷状态，缺陷级别，缺陷优先级，测试版本，测试阶段，缺陷类型，重现步骤（缺陷描述），实际结果，预期结果，缺陷所属模块，提交人，提交时间，修改人，修改时间，关闭时间，附件`

> 1 缺陷ID：缺陷编号，bug管理系统自动生成的编号
>
> 
>
> 2 缺陷标题：对发现的bug通过简洁的文字进行描述
>
> 
>
> 3 缺陷状态：
>
> 1.测试发现问题，使用bug管理工具提单至开发人员，bug状态为`new`
>
> 2.开发打开bug单，确认问题是否存在，bug状态为`open`
>
> 3.开发确认是bug，将bug修改完成后，bug状态为`fixed`
>
> 4.开发给出依据确认不是bug，bug状态为`rejected`
>
> 5.测试回归bug，验证通过，bug状态为`closed`
>
> 6.测试同意开发给出不是bug的依据，关闭问题单，bug状态为`closed`
>
> 7.开发确认测试提交的问题是问题，延迟解决，bug状态为`pending` （挂起）
>
> 8.测试回归bug，验证不通过，bug状态为 `reopen `
>
> bug状态流程图：
>
> ![](C:\Users\Administrator\Desktop\张天一\它石阶段\测试理论\缺陷生命周期流程图.png)
>
> 需要关闭的bug：
>
> 1. 回归通过
> 2. 确认非问题和无效

> 4 缺陷级别：
>
> `致命`：程序的主要功能丧失，闪退，崩溃，报5xx，无法注册，无法登录
>
> `严重`：次要功能没有实现，引发部分功能无法正常使用，如：无法删除商品，新增商品失败，无法编辑商品
>
> `一般`：基本功能实现，但是边界值错误，或者某些重要功能的异常情况错误
>
> `轻微`：界面排版错误，系统操作不方便，但可以使用
>
> 
>
> 5 缺陷优先级：
>
> 1（致命），2（严重），3（一般），4（轻微）
>
> 
>
> 6 测试版本：即本次发布新功能的版本号
>
> 
>
> 7 测试阶段：
>
> `BVT` （build verification testing）：冒烟测试
>
> `SIT` （system intergration testing）：系统集成测试
>
> `UAT` （user acceptance testing）：用户验收测试
>
> `UT `  (Unit Testing)：单元测试
>
> 
>
> 8 `测试类型`：（`缺陷产生的主要原因`）
>
> 代码错误：程序编码错误
>
> 文档缺陷：文档不容易理解，文档缺失，文档描述错误
>
> 设计缺陷：主要指的是需求设计不合理
>
> 配置缺陷：软件在安装时出现的错误
>
> 界面缺陷：系统界面排版错误，界面文字错误
>
> 功能缺陷：需求规格说明书中要求的功能没有实现
>
> 性能缺陷：业务处理性能低，查询性能低，统计报表性能低
>
> 
>
> 9.缺陷描述：又称重现步骤，指导开发人员具体怎么重现问题
>
> 10.实际结果：执行用例后得到的结果
>
> 11.预期结果：需求中期望得到的结果
>
> 12.bug所属模块：bug在哪个模块下测试发现的
>
> 13.提交人：发现问题的软件测试工程师
>
> 14.提交时间：发现问题的时间
>
> 15.修改人：缺陷修复对应的开发人员
>
> 16.修改时间：开发修复完bug的时间
>
> 17.关闭时间：软件测试工程师关闭问题的时间
>
> 18.附件：主要是为了开发人员快速定位问题，提供分析问题的依据如：截图，视频，抓包，日志
>
> 文件

### 10.8 提单的5C原则

> `correct（准确）`：问题单中每个组成部分描述准确，不会引发误解
>
> `clear（清晰）`：问题单中的每个组成部分描述信息，易于理解
>
> `concise（简介）`：只包含必不可少的信息，不包含任何多余的信息
>
> `complete（完整）`：包含重现该缺陷的完整步骤
>
> `consistent（一致）`：按照一致的格式书写全部的问题单

### 10.9 缺陷的生命周期

> `提交，确认，分配，修改，验证，关闭`

### 10.10 常用的bug管理工具

> 禅道（zentao），bugfree，QC，matis，DTS（华为），TAPD（腾讯），jira...

> 禅道的使用：
>
> 谁维护：测试组长或测试经理

## 11 配置库管理工具

### 11.1 常用的配置可管理工具

> SVN，Git

### 11.2 SVN的使用

> 安装和使用
>
> 连接服务器
>
> 上传文件
>
> 下载文件
>
> 修改文件
>
> 查看文件
>
> 恢复删除的文件
>
> 重新定位
>
> 给文件加锁和解锁



## 12 测试报告

> `概念`：主要是对测试结果，测试过程中的质量和产品的质量进行度量，总结和描述
>
> `参考依据`：测试计划，测试用例执行结果，缺陷数量
>
> `负责人`：测试组长和测试经理
>
> `时间`：测试用例执行完成达到测试结束标准，时间为1-2天
>
> `评审人`：组内软件测试工程师，开发代表，产品经理，测试经理，项目经理，QA

测试报告组成：

> `项目背景，测试目的，测试范围，测试策略，测试环境，测试工具，人员组成，人力资源和工作量的数据统计，用例数，缺陷数，遗留问题，测试风险`

`测试策略`：冒烟，功能，回归，接口，兼容，安全，性能...

测试用例数据统计：

> 三个月项目的测试用例数在`1200-1500`左右
>
> 一个月迭代一次项目用例数在`200`左右

缺陷数据统计：

> 三个月项目缺陷数在`270-300`左右
>
> 一个月迭代项目的缺陷数在`80-100`左右
>
>  
>
> 项目中bug发现越多，质量越好吗？
>
> 不，发现的bug多，说明藏的bug也多

测试时间安排：

> 假设项目第一个版本研发周期是3个月，大概可用工作日为66天
>
> 1.需求分析：10%-20%左右时间，如：10天2.测试计划：2-5天，如3天
>
> 3.测试方案：1-2周，如：5天
>
> 4.测试用例：30%左右时间如：20天
>
> 5.测试执行：40%时间左右如：26天
>
> 6.测试报告：1-2天时间如：2天
>
> 项目组测试人员2名，人均每天编写用例数35条/天左右
>
> 人均每天执行用例数27，根据模块复杂程度，平均40左右
>
> (35*2) *20=1400条用例，总计bug数：300个左右，我发现了160多个bug（体现自己的能力）
>
> `tips`:上面的数据只是合理数据范围，不是写死的



## 13 质量

### 13.1 质量的范围

> 外部质量：明确的需求
>
> 内部质量：隐含的需求
>
> 使用质量：用户在使用过程中对产品的质量进行评估

### 13.2 质量的三要素

> `技术，流程，组织`

### 13.3 CMMI 等级

> CMMI：软件能力成熟度模型综合
>
> `初始级，受管理级，已定义级，定量管理级，持续优化级`

### 13.4 质量的六大特性及27个子特性

> `功能性`：适合性，准确性，互操作性，安全保密性，功能性的依从性
>
> `可靠性`：成熟性，容错性，易恢复性，可靠性的依从性
>
> `易用性`：易理解性，易学性，易操作性，吸引性，易用性的依从性
>
> `效率`：时间特性，资源的利用性，效率的依从性
>
> `维护性`：易分析性，易改变性，稳定性，易测试性，维护性的依从性
>
> `可移植性`：适应性，易安装性，共存性，易替换性，可移植性的依从性

## 14 项目中的文档

> `需求文档`：用户需求，产品需求，需求规格说明书
>
> `开发文档`：可行性分析报告，概要设计，详细设计
>
> `测试文档`：需求分析，测试计划，测试方案，测试用例，bug清单，测试报告
>
> `项目文档`：项目计划，**版本计划**

> 版本计划：针对一个升级版本做的计划，内容包括：版本范围，进度安排，人员分配，风险等

## 15 测试流程

> 1.产品经理进行需求调研，搜索用户的需求，整理出一份文档：` 需求规格说明书`
>
> 2.产品经理组织开发和测试，召开需求讲解会议，会议结束后，开发和测试均得到 `需求规格说明书`
>
> 3.开发和测试深入了解需求文档， `提出对需求文档有疑问的地方 `
>
> 4.产品经理召开会议给测试和开发` 澄清疑问`，如果过程中，需求不明确，产品得找客户确认
>
> ​    问题澄清的过程，也是需求测试的过程
>
> 5.软件测试工程师对 `自己负责的模块进行需求分析`，完成后组织测试内部人员和开发人员`进行评审 `
>
> 6.评审后根据评审意见修改需求分析文档， `测试经理开始编写测试计划` ，安排后期测试过程中 `人力投入` 和各阶段 `时间安排`
>
> 7.软件测试工程师，开始 `编写测试用例` ，完成后， `进行评审`
>
> 8.开发编码完成后，从**SVN**上获取安装包，**测试组长** `搭建测试环境`
>
> 9.软件测试工程师开始执行 `冒烟测试` ，通过后，进行正式的测试执行，如果不通过，版本打回
>
> 10. `正式测试` 分为三轮，达到测试结束标准，终止测试
>
> 11.测试经理开始编写测试报告，软件提交 `预发布流程` ，审核通过后，开始安排上线时间点
>
> 12.上线后对主功能进行测试， `成功上线后` ，开始进行 `下一轮需求迭代 `

## 16 测试流程中的一些异常情况及解决方法

### 1 需求分析

> 1  你们是从什么时候，开始进入到项目的
>
> 2  需求不明确的情况下，如何测试（54）
>
> 3  需求经常变更，测试人员如何测试？

### 2  测试计划

> 1  项目什么时候可以结束（26）
>
> 2  项目中的测试计划是自己写的吗（29）
>
> 3  软件测试的风险体现在哪方面（84）

### 3  测试方案

> 1  项目中的测试点有多少（11）

### 4  测试用例

> 1  每天写用例的效率是多少（14）
>
> 2  项目写了多少用例（13）
>
> 3  如何编写一个好的测试用例？（72）
>
> 4  测试用例的优先级是如何划分的，分布情况（80）

### 5  测试执行

#### 环境搭建

> 1  项目环境怎么搭建（23）
>
> 2  环境出了问题，怎么怎么处理（24）
>
> 3  什么时候回用到linux（90）
>
> 4  怎么查看日志（97）
>
> 5  你会安装操作系统吗（101）

#### 冒烟测试

> 1  冒烟测试通过不了，怎么处理（33）
>
> 2  如果是时间紧，冒烟测试没通过呢

#### 进入正式测试-第一轮

#### 获取数据

> 1  项目中使用过fiddler码（96）
>
> 2  测试数据的来源（48）
>
> 3  测试人员需要关注数据库码？如何关注（57）
>
> 4  linux查看系统资源

#### 提交bug

> 1  用什么工具管理bug（19）
>
> 2  平均每天能发现多少bug（21）
>
> 3  缺陷的密度是多少（28）
>
> 4  开发过程bug都需要关闭吗（34）
>
> 5  开发人员认为不是bug，怎么处理（56）
>
> 6  如何确定是程序本身的问题还是电脑环境问题？（58）
>
> 7  对于无法重现的的缺陷，你如何处理？（62）
>
> 8  对于漏测的缺陷你是如何处理的？或者说上线客户投诉的bug如何处理（64）
>
> 9  到项目后期，很难再发现缺陷的情况下你是如何做的？有采取过什么有效的方法来找缺陷吗（71）
>
> 10  怎么样才算一个好的缺陷（73）
>
> 11  如何编写出高质量的缺陷（74）
>
> 12  当你发现确定是否是一个缺陷的情况下如何处理？（76）
>
> 13  开发人员修改的缺陷质量不高，如何处理（77）
>
> 14  管理缺陷的流程（79）
>
> 15  ~~缺陷的严重级别是如何划分的（81）~~
>
> 16  缺陷的优先级是如何划分的（82）
>
> 17  如何确定遗留的缺陷，遗留缺陷的比例是多少（83）
>
> 18  你发现了一个bug，提价给开发了，但是需求变更了，怎么解决？（91）
>
> 19  如果开发修复bug慢，怎么处理（110）
>
> 20  说出你印象中最深刻的bug（27）

#### 不同测试类型

> 安全测试：
>
> - 如何进行安全测试（86）
>
> 兼容性测试：
>
> - web兼容性测试的主要内容（85）
> - web测试和app测试的区别（94）
> - 手机兼容性怎么弄（98）
> - 弱网测试怎么测试（100）
> - app测试手机怎么选择（108）
>
> 自动化测试：
>
> - 自动化测试怎么做（89）
> - 做过接口自动化码（95）
>
> 单元测试：
>
> ​	单元测试由谁来做（45）
>
> 集成测试：
>
> ​	集成测试有谁来做（46）
>
> 回归测试的过程是怎么样的（49）

#### 性能测试

> 1  你们项目的性能测试是怎么做的（8）

#### 验收测试

> 1  客户现场发现的缺陷如何判断是不是漏测？（63）
>
> 2  对于漏测的缺陷你是如何处理的？或者说上线客户投诉的bug如何处理（64）
>
> 3  验收手册由谁来写（67）
>
> 4  测试人员需要参加验收测试吗？（68）



### 6  测试报告

> 1  每轮测试都要写测试报告吗（25）

#### 测试指标

> 1  如何保证测试的覆盖率（75）

### 7  上线

> 1  什么时候可以发布产品？产品发布的流程是怎么样的（59）
>
> 2  产品发布后，线上出现严重问题，你如何处理（61）
>
> 3  在发布前一两天，如果发现严重问题，你如何处理？（60）



### 8  运维

> 1  在维护期间，测试人员需要参与吗（41）
>
> 2  你们软件的维护期是多长（40）

### 9  项目总结

> 1  给你项目，你会从哪方面着手测试？（30）
>
> 2  项目的时间很紧张，你会怎么处理？（31）
>
> 3  开发延期，怎么处理（32）
>
> 4  项目中最困难的事情（102）
>
> 5  你觉得那个环节最重要（）103
>
> 6  项目中的角色
>
> - 在项目合作中，你和那些人沟通，工作流程是什么（65）
>
> 7  对公司的评价：
>
> - 认为公司流程方面那些有点和缺点（69）（70）
>
> 8  说出你印象中最深刻的bug（27）

